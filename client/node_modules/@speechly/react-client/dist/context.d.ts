import React from 'react';
import { DecoderOptions, DecoderState, BrowserClient, BrowserMicrophone, AudioSourceState } from '@speechly/browser-client';
import { TentativeSpeechTranscript, TentativeSpeechEntities, TentativeSpeechIntent, SpeechTranscript, SpeechEntity, SpeechIntent, SpeechSegment } from './types';
/**
 * The state of SpeechContext.
 *
 * Functions to initialise audio and recording as well as the state are always present,
 * however the values returned from the API will only be present when they are returned from the API.
 *
 * Individual values (transcripts, entities and intent) are reset back to undefined after current segment is finalised.
 * @public
 */
export interface SpeechContextState {
    /**
     * Connect to Speechly API.
     */
    connect: () => Promise<void>;
    /**
     * Function that initialises Speechly client, including both the API connection and the audio initialisation.
     *
     * It is optional and you don't have to call it manually,
     * it will be called automatically upon the first call to toggleRecording.
     *
     * The idea is that it provides a more fine-grained control over how the audio is initialised,
     * in case you want to give the user more control over your app.
     */
    attachMicrophone: () => Promise<void>;
    /**
     * Turns listening on. Automatically initialises the API connection and audio stack. Returns the context id for the stated utterance.
     */
    start: () => Promise<string>;
    /**
     * Turns listening off. Returns the context id for the stopped utterance.
     */
    stop: () => Promise<string>;
    /**
     * Current appId in multi-app project.
     */
    appId?: string;
    /**
     * @returns true if startContext called and listening will start.
     * Speechly will normally be listening nearly instantly after startContext.
     * Check clientState for details about browser client's state.
     */
    listening: boolean;
    /**
     * Current state of the context, whether it's idle, recording or failed, etc.
     * Use this to indicate to the user that recording is in progress or results are being fetched from the API.
     */
    clientState: DecoderState;
    /**
     * Current state of the microphone
     */
    microphoneState: AudioSourceState;
    /**
     * Last tentative transcript received from the API. Resets after current segment is finalised.
     */
    tentativeTranscript?: TentativeSpeechTranscript;
    /**
     * Last tentative entities received from the API. Resets after current segment is finalised.
     */
    tentativeEntities?: TentativeSpeechEntities;
    /**
     * Last tentative intent received from the API. Resets after current segment is finalised.
     */
    tentativeIntent?: TentativeSpeechIntent;
    /**
     * Last final transcript received from the API. Resets after current segment is finalised.
     */
    transcript?: SpeechTranscript;
    /**
     * Last final entity received from the API. Resets after current segment is finalised.
     */
    entity?: SpeechEntity;
    /**
     * Last final intent received from the API. Resets after current segment is finalised.
     */
    intent?: SpeechIntent;
    /**
     * Last segment received from the API.
     */
    segment?: SpeechSegment;
    /**
     * Low-level access to underlying Speechly BrowserClient.
     */
    client?: BrowserClient;
    /**
     * Low-level access to underlying Speechly BrowserMicrophone.
     */
    microphone?: BrowserMicrophone;
}
/**
 * A React context that holds the state of Speechly SLU API client.
 * @public
 */
export declare const SpeechContext: React.Context<SpeechContextState>;
/**
 * Props for SpeechContext provider, which are used to initialise API client.
 * @public
 */
export interface SpeechProviderProps extends DecoderOptions {
    /**
     * Whether to disable reacting to tentative items. Set this to true if you don't use them.
     */
    disableTentative?: boolean;
    children?: React.ReactNode;
}
interface SpeechProviderState {
    client?: BrowserClient;
    microphone?: BrowserMicrophone;
    clientState: DecoderState;
    microphoneState: AudioSourceState;
    listening: boolean;
    appId?: string;
    segment?: SpeechSegment;
    tentativeTranscript?: TentativeSpeechTranscript;
    transcript?: SpeechTranscript;
    tentativeEntities?: TentativeSpeechEntities;
    entity?: SpeechEntity;
    tentativeIntent?: TentativeSpeechIntent;
    intent?: SpeechIntent;
}
/**
 * The provider for SpeechContext.
 *
 * Make sure you have only one SpeechProvider in your application,
 * because otherwise the audio will be mixed up and unusable.
 *
 * It is possible to switch the props on the fly, which will make provider stop current client if it's running
 * and start a new one.
 * @public
 */
export declare class SpeechProvider extends React.Component<SpeechProviderProps, SpeechProviderState> {
    client?: BrowserClient;
    constructor(props: SpeechProviderProps);
    readonly componentDidMount: () => Promise<void>;
    readonly connect: () => Promise<void>;
    readonly attachMicrophone: () => Promise<void>;
    readonly start: () => Promise<string>;
    readonly stop: () => Promise<string>;
    render(): JSX.Element;
    componentDidUpdate(prevProps: SpeechProviderProps): Promise<void>;
    componentWillUnmount(): Promise<void>;
    private readonly createClient;
    private readonly onClientStateChange;
    private readonly onSegmentChange;
    private readonly onTentativeTranscript;
    private readonly onTranscript;
    private readonly onTentativeEntities;
    private readonly onEntity;
    private readonly onTentativeIntent;
    private readonly onIntent;
}
export {};
